{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 168 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: nltk>=3.1 in /home/roch/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/roch/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-bec4ba3f7ac1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-bec4ba3f7ac1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -m textblob.download_corpora\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 413840 reviews.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "reviewsDF = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "reviewsDF['Brand Name'] = reviewsDF['Brand Name'].str.lower()\n",
    "reviews = reviewsDF.Reviews.tolist()\n",
    "brands = reviewsDF['Brand Name'].tolist()\n",
    "ratings = reviewsDF['Rating'].tolist()\n",
    "print(\"Loaded \" + str(len(reviews)) + \" reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://simply-python.com/2014/03/14/saving-output-of-nltk-text-concordance/  \n",
    "\n",
    "import nltk\n",
    "def get_all_phrases_containing_tar_wrd(target_word, tar_passage, left_margin = 5, right_margin = 5):\n",
    "    \"\"\"\n",
    "        Function to get all the pharses that contain the target word in a text/passage tar_passage.\n",
    "        Workaround to save the output given by nltk Concordance function\n",
    "        \n",
    "        str target_word --> aspect to be searched for\n",
    "        str tar_passage  --> sentence extracted from a customer review\n",
    "        int left_margin int right_margin --> left_margin and right_margin allocate the number of words/punctuation before and after target word\n",
    "        Left margin will take note of the beginning of the text\n",
    "    \"\"\"\n",
    "     \n",
    "    ## Create list of tokens using nltk function\n",
    "    tokens = nltk.word_tokenize(tar_passage)\n",
    "    tokens = [x for x in tokens if len(x)>2] \n",
    "    ## Create the text of tokens\n",
    "    text = nltk.Text(tokens)\n",
    " \n",
    "    ## Collect all the index or offset position of the target word\n",
    "    c = nltk.ConcordanceIndex(text.tokens, key = lambda s: s.lower())\n",
    " \n",
    "    ## Collect the range of the words that is within the target word by using text.tokens[start;end].\n",
    "    ## The map function is use so that when the offset position - the target range < 0, it will be default to zero\n",
    "    \n",
    "    concordance_txt = ([text.tokens[  list(map(lambda x: x-5 if (x-left_margin)>0 else 0,[offset]))[0]:offset+right_margin] for offset in c.offsets(target_word)])\n",
    "\n",
    "    ## join the sentences for each of the target phrase and return it\n",
    "    return [''.join([x+' ' for x in con_sub]) for con_sub in concordance_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 155302 phrases from the reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>phrase</th>\n",
       "      <th>rating</th>\n",
       "      <th>aspect</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samsung</td>\n",
       "      <td>Then needed new battery well</td>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samsung</td>\n",
       "      <td>stay charged had buy new battery</td>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samsung</td>\n",
       "      <td>But the camera works great the video</td>\n",
       "      <td>5</td>\n",
       "      <td>camera</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>samsung</td>\n",
       "      <td>also notice that battery life lasts little bit</td>\n",
       "      <td>5</td>\n",
       "      <td>battery</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samsung</td>\n",
       "      <td>battery life great</td>\n",
       "      <td>3</td>\n",
       "      <td>battery</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand                                           phrase  rating   aspect  \\\n",
       "0  samsung                    Then needed new battery well        2  battery   \n",
       "1  samsung                stay charged had buy new battery        2  battery   \n",
       "2  samsung            But the camera works great the video        5   camera   \n",
       "3  samsung  also notice that battery life lasts little bit        5  battery   \n",
       "4  samsung                              battery life great        3  battery   \n",
       "\n",
       "   review_id  \n",
       "0          6  \n",
       "1          7  \n",
       "2          8  \n",
       "3          8  \n",
       "4          9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "## Select the aspects we believe are relevant \n",
    "relevant_aspects = ['battery', 'screen', 'camera', 'performance']\n",
    "\n",
    "## Make lists for each of the columns that we will have in our new dataframe\n",
    "phrases = []\n",
    "brand = []\n",
    "rating = []\n",
    "aspects = []\n",
    "review_num = []\n",
    "counter = 0\n",
    "# Loop through all the reviews\n",
    "for review in reviews:\n",
    "    try:\n",
    "        # Break the reviews in sentences and loop through them\n",
    "        for sentence in sent_tokenize(review):\n",
    "            for  important_word in relevant_aspects:\n",
    "                # Get all the phrases containing one of the topic names\n",
    "                # Create append list of phrases, aspects, ratings etc to create a DF\n",
    "                phrases_in_sentence = get_all_phrases_containing_tar_wrd(important_word, sentence, left_margin = 5, right_margin = 5) \n",
    "                for phrase in phrases_in_sentence:\n",
    "                    brand.append(brands[counter])\n",
    "                    rating.append(ratings[counter])\n",
    "                    aspect = 'other'\n",
    "                    for imp_word in relevant_aspects:\n",
    "                        if imp_word in phrase.lower():\n",
    "                            aspect = imp_word\n",
    "                    aspects.append(aspect)\n",
    "                    phrases.append(phrase)\n",
    "                    review_num.append(counter)\n",
    "    except:\n",
    "        pass\n",
    "    counter = counter + 1\n",
    "\n",
    "print('Extracted ' + str(len(phrases)) + ' phrases from the reviews')\n",
    "\n",
    "# Create the phrases dataframe\n",
    "phrasesDF = pd.DataFrame()\n",
    "phrasesDF['brand'] = brand \n",
    "phrasesDF['phrase'] = phrases\n",
    "phrasesDF['rating'] = rating\n",
    "phrasesDF['aspect'] = aspects\n",
    "phrasesDF['review_id'] = review_num\n",
    "phrasesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blobber' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-614a51cdf0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     })\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mphrasesDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdYlGn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-614a51cdf0de>\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(phrase)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnb_blob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblobber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msia_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blobber' is not defined"
     ]
    }
   ],
   "source": [
    "def get_scores(phrase):\n",
    "    blob = TextBlob(phrase)\n",
    "    nb_blob = blobber(phrase)\n",
    "    sia_scores = sia.polarity_scores(phrase)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'phrase': phrase,\n",
    "        'textblob': blob.sentiment.polarity,\n",
    "        'textblob_bayes': nb_blob.sentiment.p_pos - nb_blob.sentiment.p_neg,\n",
    "        'nltk': sia_scores['compound'],\n",
    "    })\n",
    "\n",
    "scores = phrasesDF.phrase.apply(get_scores)\n",
    "scores.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobber = Blobber(analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************\n",
      "  Resource \u001b[93mmovie_reviews\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('movie_reviews')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mcorpora/movie_reviews\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - '/home/roch/nltk_data'\n",
      "    - '/home/roch/anaconda3/nltk_data'\n",
      "    - '/home/roch/anaconda3/share/nltk_data'\n",
      "    - '/home/roch/anaconda3/lib/nltk_data'\n",
      "    - '/usr/share/nltk_data'\n",
      "    - '/usr/local/share/nltk_data'\n",
      "    - '/usr/lib/nltk_data'\n",
      "    - '/usr/local/lib/nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    },
    {
     "ename": "MissingCorpusError",
     "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mmovie_reviews\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('movie_reviews')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/movie_reviews.zip/movie_reviews/\u001b[0m\n\n  Searched in:\n    - '/home/roch/nltk_data'\n    - '/home/roch/anaconda3/nltk_data'\n    - '/home/roch/anaconda3/share/nltk_data'\n    - '/home/roch/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mneg_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mpos_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mmovie_reviews\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('movie_reviews')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/movie_reviews\u001b[0m\n\n  Searched in:\n    - '/home/roch/nltk_data'\n    - '/home/roch/anaconda3/nltk_data'\n    - '/home/roch/anaconda3/share/nltk_data'\n    - '/home/roch/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a74b41f6936e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     })\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphrasesDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdYlGn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-a74b41f6936e>\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(phrase)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'phrase'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'textblob'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;34m'textblob_bayes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnb_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnb_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     })\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36msentiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnamedtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \"\"\"\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/base.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Analyze text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingCorpusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
     ]
    }
   ],
   "source": [
    "def get_scores(phrase):\n",
    "    blob = TextBlob(phrase)\n",
    "    nb_blob = blobber(phrase)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'phrase': phrase,\n",
    "        'textblob': blob.sentiment.polarity,\n",
    "        'textblob_bayes': nb_blob.sentiment.p_pos - nb_blob.sentiment.p_neg,\n",
    "    })\n",
    "\n",
    "scores = phrasesDF.phrase.apply(get_scores)\n",
    "scores.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.275, subjectivity=0.8194444444444444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This restaurant was great, but I'm not sure if I'll go there again.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************\n",
      "  Resource \u001b[93mmovie_reviews\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('movie_reviews')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mcorpora/movie_reviews\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - '/home/roch/nltk_data'\n",
      "    - '/home/roch/anaconda3/nltk_data'\n",
      "    - '/home/roch/anaconda3/share/nltk_data'\n",
      "    - '/home/roch/anaconda3/lib/nltk_data'\n",
      "    - '/usr/share/nltk_data'\n",
      "    - '/usr/local/share/nltk_data'\n",
      "    - '/usr/lib/nltk_data'\n",
      "    - '/usr/local/lib/nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    },
    {
     "ename": "MissingCorpusError",
     "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mmovie_reviews\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('movie_reviews')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/movie_reviews.zip/movie_reviews/\u001b[0m\n\n  Searched in:\n    - '/home/roch/nltk_data'\n    - '/home/roch/anaconda3/nltk_data'\n    - '/home/roch/anaconda3/share/nltk_data'\n    - '/home/roch/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mneg_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mpos_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mmovie_reviews\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('movie_reviews')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/movie_reviews\u001b[0m\n\n  Searched in:\n    - '/home/roch/nltk_data'\n    - '/home/roch/anaconda3/nltk_data'\n    - '/home/roch/anaconda3/share/nltk_data'\n    - '/home/roch/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6d4ff813c7d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblobber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This restaurant was great, but I'm not sure if I'll go there again.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36msentiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnamedtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \"\"\"\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/base.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Analyze text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingCorpusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
     ]
    }
   ],
   "source": [
    "blobber = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "blob = blobber(\"This restaurant was great, but I'm not sure if I'll go there again.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_polarity(reviewsDF):\n",
    "    return TextBlob(reviewsDF).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tb = phrasesDF.phrase.apply(detect_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.136364\n",
       "1    0.136364\n",
       "2    0.800000\n",
       "3   -0.187500\n",
       "4    0.800000\n",
       "Name: phrase, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155302, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasesDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 155302 rows and 5 columns\n"
     ]
    }
   ],
   "source": [
    "nRow, nCol = phrasesDF.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentimentIntensityAnalyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-83a9b8378343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_analyser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent_analyser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compound\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentimentIntensityAnalyzer' is not defined"
     ]
    }
   ],
   "source": [
    "sent_analyser = SentimentIntensityAnalyzer()\n",
    "def sentiment(phrase):\n",
    "    return (sent_analyser.polarity_scores(phrase)[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasesDF[\"text_sentiment\"] = phrasesDF.phrase.apply(detect_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>phrase</th>\n",
       "      <th>rating</th>\n",
       "      <th>aspect</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text-sentiment</th>\n",
       "      <th>text_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samsung</td>\n",
       "      <td>Then needed new battery well</td>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samsung</td>\n",
       "      <td>stay charged had buy new battery</td>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>7</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samsung</td>\n",
       "      <td>But the camera works great the video</td>\n",
       "      <td>5</td>\n",
       "      <td>camera</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>samsung</td>\n",
       "      <td>also notice that battery life lasts little bit</td>\n",
       "      <td>5</td>\n",
       "      <td>battery</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samsung</td>\n",
       "      <td>battery life great</td>\n",
       "      <td>3</td>\n",
       "      <td>battery</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand                                           phrase  rating   aspect  \\\n",
       "0  samsung                    Then needed new battery well        2  battery   \n",
       "1  samsung                stay charged had buy new battery        2  battery   \n",
       "2  samsung            But the camera works great the video        5   camera   \n",
       "3  samsung  also notice that battery life lasts little bit        5  battery   \n",
       "4  samsung                              battery life great        3  battery   \n",
       "\n",
       "   review_id  text-sentiment  text_sentiment  \n",
       "0          6        0.136364        0.136364  \n",
       "1          7        0.136364        0.136364  \n",
       "2          8        0.800000        0.800000  \n",
       "3          8       -0.187500       -0.187500  \n",
       "4          9        0.800000        0.800000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f71b9426d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAEkCAYAAAARhClzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3df7gcVZ3n8fdHfht+BAhcIEQiCAqaXYEIcXA1K7oTiBJ8hFkQIXHRDCOOsGZGMjrrqDvOBJ9VQWFgojAJOww/BJSgsCqQuyxqUFAkYFQCZkhITPgZCCh64bt/1LnYuem+Xbm3u/p038/refq5XVWnq79Vt09/q06dOq2IwMzMzDrvFZ0OwMzMzApOymZmZplwUjYzM8uEk7KZmVkmnJTNzMwy4aRsZmaWCSdlMzOzTDgp9wBJb5H0A0kbJT0p6fuS3tTpuMxsZCS9T9LdkjZJWifpFklv6XRc1n5Oyl1O0q7At4CvAHsAE4HPAC9sxTq2bU90Zra1JH0MuAD4B6APeBXwT8CsDsbk74iKOCl3v0MAIuKqiHgxIn4bEd+NiPsAJH1I0gpJz0r6uaQj0vxVks6TdB/wnKRtJe0n6XpJj0n6taSPDr6JpFdImi/pIUlPSLpW0h5p2WRJIWm2pEckPS7pkx3YF2ZdTdJuwGeBsyPihoh4LiL+EBE3RcRfSzpK0g8lPZ3OoC+StH3N60PShyU9mOr8/5R0UHrNM6ne1pZ/l6R70/p+IOk/1Cyr9x0x+B0w+H3ynkp30BjgpNz9fgW8KGmxpOMk7T64QNLJwKeBM4BdgROAJ2peeyowExgPvATcBPyM4mz7WOBcSX+ayn4UOBF4G7Af8BRw8ZBY3gK8Nr32U5IObd1mmo0JbwZ2BL7RYPmLwH8HJqSyxwIfHlJmBnAkMA34OLAQOA2YBLyBot6TDtAvB/4c2BP4Z2CJpB1q1vXyd0REDAAPAf8J2I2iRe5fJe078s21oZyUu1xEPEORDAP4KvCYpCWS+oAPAp+PiB9HYWVE/HvNy78cEasj4rfAm4C9IuKzEfH7iHg4re+UVPbPgU9GxJqIeIEi2Z80pFnrM+lM/WcUyf0/tnHTzXrRnsDjKQFuISLuiYhlETEQEasoEunbhhQ7PyKeiYgHgPuB70bEwxGxEbgFODyV+xDwzxFxV2plW0xx2WtazbpqvyOIiK9HxNqIeCkirgEeBI5qzaYbgK8T9ICIWAHMAZD0OuBfKa5JTaI4sm1kdc3zA4D9JD1dM28b4P/VLP+GpJdqlr9Icc1r0G9qnj8P7Fx+K8yMoiVrgqRt6yVmSYcAXwSmAq+k+A6/Z0ix9TXPf1tnep/0/ABgtqS/rFm+PUVL2KDa7wgknQF8DJicZu1McdZuLeIz5R4TEb8AFlE0U60GDhqueM3z1cCvI2J8zWOXiDi+ZvlxQ5bvGBGPtmM7zMaoHwK/o7hUVM8lwC+AgyNiV+ATgEb4XquBzw2p06+MiKtqyrz8HSHpAIrWs48Ae0bEeIoz8ZG+v9XhpNzlJL1O0jxJ+6fpSRTXgZYBXwP+StKRKrwmVax6fgQ8kzp27CRpG0lvqLm16lLgc4Ovl7SXpI71BjXrRamJ+VPAxZJOlPRKSdul/iKfB3YBngE2pVaxvxjF230VOEvS0en7YZykmZJ2aVB+HEWSfgxA0gcoDv6thZyUu9+zwNHAXZKeo0jG9wPzIuLrwOeAf0vlvklx29QWIuJF4N3AG4FfA49TJPXdUpELgSXAdyU9m97n6DZtk9mYFRFfpGgi/luKBLia4uz0m8BfAe+jqM9fBa4ZxfvcTXFd+SKKjpsrSZfBGpT/OfAFirP59cAU4PsjfX+rTxHRvJSZmZm1nc+UzczMMuGkbGZmlgknZTMzs0w4KZuZmWUii8FDJkyYEJMnTx62zHPPPce4ceOqCahFHHN1ujHuMjHfc889j0fEXhWF1HKu2/lwzNUYdb2OiI4/jjzyyGhm6dKlTcvkxjFXpxvjLhMzcHdkUEdH+nDdzodjrsZo67Wbr83MzDLhpGxmZpYJJ2UzM7NMZNHRy7rL5Pnfblpm1YKZFURiZt2qzPfIvCkDzGlSrte+a3ymbGZmlgknZTMzs0w4KZuZmWXCSdnMzCwTTspmZmaZcFI2MzPLhJOymZlZJpyUzczMMuGkbGZmlgknZTMzs0w4KZuZmWXCY19bx3gMbTOzzflM2czMLBNOymZmZplw87WZmY15ZS6nlbFoxrhRvd5nymZjmKRtJP1U0rfS9Ksl3SXpQUnXSNo+zd8hTa9Myyd3Mm6zXuWkbDa2nQOsqJk+H/hSRBwMPAWcmeafCTwVEa8BvpTKmVmLufnabIyStD8wE/gc8DFJAt4OvC8VWQx8GrgEmJWeA1wHXCRJERFVxmyd16pmXqvPSdls7LoA+DiwS5reE3g6IgbS9BpgYno+EVgNEBEDkjam8o8PXamkucBcgL6+Pvr7+4cNYtOmTU3L5GYsxzxvykDzQi3St1Pz92vV/6FV2zXa/dw0KUuaBFwB7AO8BCyMiAsl7QFcA0wGVgF/FhFPpaPtC4HjgeeBORHxkxFHaGYtJ+ldwIaIuEfS9MHZdYpGiWWbz4xYCCwEmDp1akyfPr1esZf19/fTrExuxnLMcyo8U543ZYAvLB8+Ta06bXpL3qtV27VoxrhR7ecy15QHgHkRcSgwDThb0mHAfOC2dO3ptjQNcBxwcHrMpWj6MrO8HAOcIGkVcDVFs/UFwHhJg9+C+wNr0/M1wCSAtHw34MkqAzYbC5om5YhYN3imGxHPUnQKmUhxjWlxKrYYODE9nwVcEYVlFJV835ZHbmYjFhF/ExH7R8Rk4BTg9og4DVgKnJSKzQZuTM+XpGnS8tt9Pdms9bbqmnK6DeJw4C6gLyLWQZG4Je2dir187SkZvC61bsi6fN0pQ2ViLnPtpcx2t2o9ABue3MhXrrxx2DJTJu5Wal1VyfTzcR5wtaS/B34KXJbmXwb8b0krKc6QT+lQfGY9rXRSlrQzcD1wbkQ8U1w6rl+0zrwtjqh93SlPZWIuc+2lzHWeVq0H4CtX3ljZtadWyeXzERH9QH96/jBwVJ0yvwNOrjQwszGo1H3KkrajSMhXRsQNafb6wWbp9HdDmv/ytaek9rqUmZmZNdA0Kafe1JcBKyLiizWLaq8xDb32dIYK04CNg83cZmZm1liZ5utjgNOB5ZLuTfM+ASwArpV0JvAIf2zaupnidqiVFLdEfaClEZuZmfWopkk5Iu6k/nVigGPrlA/g7FHGZV3Oo/6YmW09j31tZmaWCSdlMzOzTDgpm5mZZcJJ2czMLBNOymZmZplwUjYzM8uEf0/ZzMy6Vq/dfukzZTMzs0w4KZuZmWXCSdnMzCwTTspmZmaZcFI2MzPLhJOymZlZJpyUzczMMuGkbGZmlgknZTMzs0x4RK8uUGbEmlULZlYQiZmZtZPPlM3MzDLhpGxmZpYJJ2UzM7NM+Jpyj/B1ZzOz7uczZTMzs0w4KZuZmWXCSdnMzCwTTspmZmaZcFI2MzPLhJOymZlZJnxLlJnZGLD80Y3MKXHrpHWWk7KNGb6X28xy5+ZrszFK0iRJSyWtkPSApHPS/D0kfU/Sg+nv7mm+JH1Z0kpJ90k6orNbYNZ7nJTNxq4BYF5EHApMA86WdBgwH7gtIg4GbkvTAMcBB6fHXOCS6kM2621Nk7KkyyVtkHR/zTwfSZt1uYhYFxE/Sc+fBVYAE4FZwOJUbDFwYno+C7giCsuA8ZL2rThss55W5pryIuAi4IqaeYNH0gskzU/T57H5kfTRFEfSR7cyYDNrPUmTgcOBu4C+iFgHReKWtHcqNhFYXfOyNWneuiHrmktxJk1fXx/9/f3DvvemTZualslNN8bctxPMmzLQ6TC2SjfGPNrPRtOkHBF3pApbaxYwPT1fDPRTJOWXj6SBZZLGS9p3sIKbWX4k7QxcD5wbEc9Iali0zrzYYkbEQmAhwNSpU2P69OnDvn9/fz/NyuSmG2P+ypU38oXl3dW3d96Uga6LedGMcaP6bIx0a0d1JA0+mt4arTpSLBNLmZirPHItu/9adURd5Wcsh8+0pO0oEvKVEXFDmr1+8GA6NU9vSPPXAJNqXr4/sLa6aM16X6sPQUodSYOPprdGq+4tXHXa9KZlysRc5b2OZWKG1p0FlH2/Vuj0Z1rFKfFlwIqI+GLNoiXAbGBB+ntjzfyPSLqa4rLURreCmbXWSL/FfCRt1v2OAU4Hlku6N837BEUyvlbSmcAjwMlp2c3A8cBK4HngA9WGa9b7RpqUfSRtlSgz4AfAvCltDqQHRcSd1G/dAji2TvkAzm5rUGZjXNOkLOkqik5dEyStAf4OH0mbmZm1XJne16c2WOQjaTMzsxbyiF5mZmaZcFI2MzPLhJOymZlZJpyUzczMMuGkbGZmlgknZTMzs0w4KZuZmWXCSdnMzCwT3fWbWF1m+aMbm/54w6oFMyuKxsyqVHaI2Gb8HTG2OCmbbaUyX7b+IjWzkXDztZmZWSaclM3MzDLhpGxmZpYJX1PusFZ1BjEzs+7nM2UzM7NM+EzZzCxjrWpNmzelJauxNvOZspmZWSZ8pmzWBmXObhbNGFdBJGbWTZyUzcxqlDmgmjdloOlofWYj4eZrMzOzTDgpm5mZZcJJ2czMLBNOymZmZplwUjYzM8uEk7KZmVkmnJTNzMwy4fuU6/CP2JuZWSf4TNnMzCwTPlMeoXKj/lQQSIstf3TjmB6pyD+l2b38v7Ne4DNlMzOzTLTlTFnSDOBCYBvgaxGxoB3vY2bVakfdHuutM2a1Wp6UJW0DXAy8E1gD/FjSkoj4eavfayTcxGU2MrnXbbNe0I7m66OAlRHxcET8HrgamNWG9zGzarlum7WZIqK1K5ROAmZExAfT9OnA0RHxkSHl5gJz0+RrgV82WfUE4PGWBtt+jrk63Rh3mZgPiIi9qgimGdftzTjmavRqzA3rdTuuKavOvC0yf0QsBBaWXql0d0RMHU1gVXPM1enGuLswZtftxDFXYyzG3I7m6zXApJrp/YG1bXgfM6uW67ZZm7UjKf8YOFjSqyVtD5wCLGnD+5hZtVy3zdqs5c3XETEg6SPAdyhum7g8Ih5owapLN4dlxDFXpxvj7qqYXbc345irMeZibnlHLzMzMxsZj+hlZmaWCSdlMzOzTGSblCWdLOkBSS9Jati9XNIMSb+UtFLS/CpjrBPLHpK+J+nB9Hf3BuVelHRvenSko0yz/SZpB0nXpOV3SZpcfZRbxNQs5jmSHqvZtx/sRJxDYrpc0gZJ9zdYLklfTtt0n6Qjqo6xaq7b7eW63X5trdcRkeUDOJRi4IF+YGqDMtsADwEHAtsDPwMO62DMnwfmp+fzgfMblNvU4X3bdL8BHwYuTc9PAa7pgpjnABd1Ms46cb8VOAK4v8Hy44FbKO4Bngbc1emYK9gnrtvti9N1u5qY21avsz1TjogVEdFsJKDchv2bBSxOzxcDJ3YwluGU2W+123IdcKykeoNHVCW3/3UpEXEH8OQwRWYBV0RhGTBe0r7VRNcZrttt5bpdgXbW62yTckkTgdU102vSvE7pi4h1AOnv3g3K7SjpbknLJHWicpfZby+XiYgBYCOwZyXR1Vf2f/3e1Fx0naRJdZbnJrfPcC5y2y+u2+3Ti3V7xJ/ftvx0Y1mSbgX2qbPokxFxY5lV1JnX1nu8hot5K1bzqohYK+lA4HZJyyPiodZEWEqZ/Vb5vm2iTDw3AVdFxAuSzqI4G3h72yMbndz2c0u4brtub4VerNsj3scdTcoR8Y5RrqLyYf+Gi1nSekn7RsS61FSxocE61qa/D0vqBw6nuKZSlTL7bbDMGknbArsxfHNNuzWNOSKeqJn8KnB+BXGNVk8OXem67bq9FXqxbo/489vtzde5Dfu3BJidns8GtjgjkLS7pB3S8wnAMUDVv0dbZr/VbstJwO2RejB0SNOYh1yzOQFYUWF8I7UEOCP11pwGbBxsJh3jXLdHxnU7DyOv153uxTZM77b3UBxtvACsB76T5u8H3Dykl9uvKI5GP9nhmPcEbgMeTH/3SPOnAl9Lz/8EWE7Rw3A5cGaHYt1ivwGfBU5Iz3cEvg6sBH4EHJjBZ6JZzP8IPJD27VLgdRnEfBWwDvhD+jyfCZwFnJWWC7g4bdNyGvRG7qWH63bbY3Xdbn+8bavXHmbTzMwsE93efG1m1tMk/b2kxyX9ptOxWPs5KXcxSask/VbSJklPSfp2mVsFJE2WFKmTx+C8OZLubG/EZmPDkLq5XtK/SNp5BOuZBMyjGEyjXs9w6zFOyt3v3RGxM7AvxfW5r3QiiNoEb2bAH+vmEcCbgL/dmhenOnUA8ERE1O3tXeL11mWclHtERPyOYnSewwAkzZT0U0nPSFot6dM1xe9If59OR/JvBi4F3pymn07r2EHS/5L0SDrav1TSTmnZdElrJJ2XmtX+RdL9kt49+CaStkvNbm9s/x4wy1NEPEox5OIbJO0m6TJJ6yQ9mpqmt4GXW6u+L+lLkp6kGIb0e8B+qV4uSuVOUDF2+NOS+iUdOvhe6Qz9PEn3Ac9J2jbN+2sVA288l96/T9Itkp6VdKtqxvKW9HVJv5G0UdIdkl5fs2yRpItTq9yzKsbOPqhm+etVjA3+ZPrO+ESa/wpJ8yU9JOkJSddK2qOd+71bOSn3CEmvBP4rsCzNeg44AxgPzAT+Qn8cYeit6e/4iNg5In5I0XPwh2l6fFp+PnAI8EbgNRQj0nyq5m33AfagOJqfC1wBvL9m+fHAuoi4t2UbatZlUhP08cBPKQa9GKCoT4cD/wWo/XGFo4GHKUYMeydwHLA21cs5kg6h6Pl7LrAXcDNwU7qVaNCpFHV+fBQjdgG8N63vEODdFAcJnwAmUOSBj9a8/hbg4BTDT4Arh2zSqcBngN0penB/Lm3nLsCtwP+h6En/Goqe6qT1nwi8LS17iqJ3sg3V6a7wfoyqW/4qYBPwNEVFXwtMaVD2AuBL6flkitFltq1ZPge4s2ZaFIn9oJp5bwZ+nZ5PB34P7FizfD/gWWDXNH0d8PFO7yc//Kj6MaRu/jvwTxQHry8AO9WUOxVYmp7PAR4Zsp7pwJqa6f8BXFsz/QrgUWB6zfv+tzqxnFYzfT1wSc30XwLfbLAd49N3xW5pehHpFrA0fTzwi5pt+WmD9awAjq2Z3pfidqJt65Ufyw9fc+h+J0bErakJbBbwfyUdRvEFsAB4A8Uvr+xAcW9iWXsBrwTu0R/HqhfFL7oMeiyKZnOgGM1I0vcpxqj9BsVR/jkj2yyzrndiRNw6OCHpKGA7YF1NnXoFm4+RXPu8nv0okjwAEfGSpNVsPq5yvXWsr3n+2zrTO6cYt6E48z2Z4jvgpVRmAsUY2QC1vcCfH3wtxQhWjUYvOwD4hqSXaua9CPRRHFRY4ubrHhERL0bEDRQf9LcA/0YxqsykiNiN4prx4DdBvZvTh857nKKyvj4ixqfHblF0XGn0Giia595PUal/GMX1NDMrkuULwISaOrVrRLy+pkyzgSPWUiQ4oPjdXopkWFvPRjP4xPsoDu7fQTH85uTBtyrx2tXAQcMsO65mu8dHxI7+ftiSk3KPSMO5zaK4zrMC2AV4MiJ+l47Q31dT/DGKI+ADa+atB/YfvDYVES9RjDH7JUl7p/eYKOlPm4TyTYrepudQXGM2M17+danvAl+QtGvq/HSQpLdtxWquBWZKOlbSdhS3S70A/KBFYe6S1vcERUvZP2zFa78F7CPp3NRJdBdJR6dllwKfk3QAgKS90veVDeGk3P1ukrQJeIai2Wl2RDxA8UPmn5X0LEXnrGsHXxARz6ey3089OKcBt1MMY/cbSY+noudRdORYJukZik4crx0umIj4LcU1q1cDN7RuM816whkUl5N+TtHZ6TqK66ulRPE71O+nuPXxcYpOW++O4neIW+EKiubxR1OMy4Yvvllsz1J0Jns3RRP3g8B/TosvpGi5+276TlpG0anNhvAwm9Zykj4FHBIR729a2MzMXuaOXtZS6d7DM4HTOx2LmVm3cfO1tYykD1F06LglIu5oVt7MzDbn5mszM7NM+EzZzMwsE1lcU54wYUJMnjx52DLPPfcc48aNqyagFnHM1enGuMvEfM899zweEXtVFFLLlanbVejGz8dwvD35GnW97vSQYhHBkUceGc0sXbq0aZncOObqdGPcZWIG7o4M6uhIH2XqdhW68fMxHG9PvkZbr918bWZmlgknZTMzs0w4KZuZmWUii45e1l0mz/920zKrFsysIBIz61a13yPzpgwwp8T3Sj299l3jM2UzM7NMOCmbmZllwknZzMwsE07KZmZmmXBSNjMzy4STspmZWSaclM3MzDLhpGxmZpYJJ2UzM7NMOCmbmZllwknZzMwsE07KZmZmmXBSNjMzy4STspmZWSaclM3MzDLRNClLmiRpqaQVkh6QdE6av4ek70l6MP3dPc2XpC9LWinpPklHtHsjzMzMekGZM+UBYF5EHApMA86WdBgwH7gtIg4GbkvTAMcBB6fHXOCSlkdtZmbWg5om5YhYFxE/Sc+fBVYAE4FZwOJUbDFwYno+C7giCsuA8ZL2bXnkZmZmPWbbrSksaTJwOHAX0BcR66BI3JL2TsUmAqtrXrYmzVs3ZF1zKc6k6evro7+/f9j33rRpU9MyuenVmOdNGWi6nqq3u1f3tZmNLaWTsqSdgeuBcyPiGUkNi9aZF1vMiFgILASYOnVqTJ8+fdj37+/vp1mZ3PRqzHPmf7vpeladNvw6Wq1X97WZjS2lel9L2o4iIV8ZETek2esHm6XT3w1p/hpgUs3L9wfWtiZcMzOz3lWm97WAy4AVEfHFmkVLgNnp+Wzgxpr5Z6Re2NOAjYPN3GZmZtZYmTPlY4DTgbdLujc9jgcWAO+U9CDwzjQNcDPwMLAS+Crw4daHbWbtJmkbST+V9K00/WpJd6XbIK+RtH2nYzTrNU2vKUfEndS/TgxwbJ3yAZw9yrjMrPPOobjbYtc0fT7wpYi4WtKlwJn4lkezlvKIXma2BUn7AzOBr6VpAW8HrktFam+DNLMW2apbosxszLgA+DiwS5reE3g6Igbvhxu81XELW3u7YxV67fazXtie2lsr+3Yqd6tlPbnth9H+b5yUzWwzkt4FbIiIeyRNH5xdp+gWtzrC1t/uWIVeu/2sF7an9tbKeVMG+MLykaWjqm+/bGa0/xsnZTMb6hjghNShc0eKa8oXUIzOt206W/atjmZt4GvKZraZiPibiNg/IiYDpwC3R8RpwFLgpFSs9jZIM2sRJ2UzK+s84GOSVlJcY76sw/GY9Rw3X5tZQxHRD/Sn5w8DR3UyHrNe5zNlMzOzTDgpm5mZZcLN19YTlj+6semvV61aMLOiaMzMRsZnymZmZplwUjYzM8uEk7KZmVkmnJTNzMwy4aRsZmaWCSdlMzOzTPiWKOuYyU1uYQLfxmRmY4vPlM3MzDLhM2UzMxvzyrTclbFoxrhRvd5J2dqiVR9wM7OxxEnZzMxK8wF3e/maspmZWSaclM3MzDLh5msbM3wLlpnlzmfKZmZmmXBSNjMzy4Sbr3uEm2bNzLqfz5TNzMwy4TNlM7MxwPcXdwefKZuZmWXCZ8qWtbJH9/OmtDkQM7MK+EzZzMwsE03PlCVdDrwL2BARb0jz9gCuASYDq4A/i4inJAm4EDgeeB6YExE/aU/oZmY21vXatfIyZ8qLgBlD5s0HbouIg4Hb0jTAccDB6TEXuKQ1YZqZmfW+pkk5Iu4AnhwyexawOD1fDJxYM/+KKCwDxkvat1XBmpmZ9bKRdvTqi4h1ABGxTtLeaf5EYHVNuTVp3rqhK5A0l+Jsmr6+Pvr7+4d9w02bNjUtk5sqY543ZaBpmTKxlIm5zHtVrW+n1sRV5WesGz/TZtZere59rTrzol7BiFgILASYOnVqTJ8+fdgV9/f306xMbqqMeU6ZEb1Om960TJmYy7xX1eZNGeALy0f/cS6zj1o1elqun2lJk4ArgH2Al4CFEXFho74knYrTrBeNtPf1+sFm6fR3Q5q/BphUU25/YO3IwzOzDhgA5kXEocA04GxJh9G4L4mZtchIk/ISYHZ6Phu4sWb+GSpMAzYONnObWXeIiHWDd01ExLPACorLUI36kphZi5S5JeoqYDowQdIa4O+ABcC1ks4EHgFOTsVvprgdaiXFLVEfaEPMZlYRSZOBw4G7aNyXZOhrtqq/SBV67fr9SLYnx74gg1rVJyQHo/2sNU3KEXFqg0XH1ikbwNkjjsbMsiFpZ+B64NyIeKYYhqC5re0vUoVcr9+P1Ei2J8e+IINa1SckB4tmjBvVZ80jepnZFiRtR5GQr4yIG9LsRn1JzKxFnJTNbDNpZL7LgBUR8cWaRY36kphZi/RGe4FZZsrcNrVoxrgKIhmRY4DTgeWS7k3zPkHjviRm1iJOyma2mYi4k/pjDkCdviRm1jpuvjYzM8uEz5S7QK/9CoqZmdXnM2UzM7NMOCmbmZllwknZzMwsE07KZmZmmXBSNjMzy4STspmZWSZ8S1QbLX90Y9NB4FctmFlRNGZmljsn5Q7zPchmZjbIzddmZmaZcFI2MzPLhJOymZlZJpyUzczMMuGkbGZmlgn3vjYzq9GqOyJ8u6ONhM+UzczMMuGkbGZmlgknZTMzs0z4mnIdZa4p+XqRmZm1mpOymVkbuMOYjYSbr83MzDLhM2Uz6yifUZr9kc+UzczMMuEzZbMa/ilNM+sknymbmZllomvOlJc/upE5Tc5ifE3JzMy6mc+UzczMMtE1Z8pmZsMZrj/AvCkDTVvazHLQljNlSTMk/VLSSknz2/EeZlY9122z9mr5mbKkbYCLgXcCa4AfS1oSET9v9XsN5eExR6/MtXsbmzpZt83GinY0Xx8FrIyIhwEkXQ3MArKouK265aXMeuZNaclbmeUi67pt1gsUEa1doXQSMCMiPpimTweOjoiPDCk3F5ibJl8L/LLJqicAj7c02PZzzNXpxrjLxHxAROxVRTDNtLFuV6EbPx/D8fbka1T1uh1nyqozb4vMHxELgYWlVyrdHRFTRxNY1Rxzdbox7i6MuS11uwpduK+H5e3J12i3pU6s+hEAAAPWSURBVB0dvdYAk2qm9wfWtuF9zKxarttmbdaOpPxj4GBJr5a0PXAKsKQN72Nm1XLdNmuzljdfR8SApI8A3wG2AS6PiAdasOqsmsNKcszV6ca4uyrmNtbtKnTVvi7B25OvUW1Lyzt6mZmZ2ch4mE0zM7NMOCmbmZllItukLOlkSQ9IeklSw+7lOQ37J2kPSd+T9GD6u3uDci9Kujc9OtJRptl+k7SDpGvS8rskTa4+yi1iahbzHEmP1ezbD3YiziExXS5pg6T7GyyXpC+nbbpP0hFVx9iLuqkuDqcb62kj3Vh/G2lrvY6ILB/AoRQDD/QDUxuU2QZ4CDgQ2B74GXBYB2P+PDA/PZ8PnN+g3KYO79um+w34MHBpen4KcE0XxDwHuKiTcdaJ+63AEcD9DZYfD9xCcQ/wNOCuTsfcC49uqYtNtqHr6ukotyW7+jvM9rStXmd7phwRKyKi2UhALw/7FxG/BwaH/euUWcDi9HwxcGIHYxlOmf1Wuy3XAcdKqjd4RFVy+1+XEhF3AE8OU2QWcEUUlgHjJe1bTXQ9rVvq4nC6sZ420pX1t5F21utsk3JJE4HVNdNr0rxO6YuIdQDp794Nyu0o6W5JyyR14suizH57uUxEDAAbgT0ria6+sv/r96bmouskTaqzPDe5fYZ7RbfUxeF0Yz1tpFfrbyMjrtcd/T1lSbcC+9RZ9MmIuLHMKurMa+s9XsPFvBWreVVErJV0IHC7pOUR8VBrIiylzH6rfN82USaem4CrIuIFSWdRnEG8ve2RjU5u+7lr9EhdHE431tNGerX+NjLi/0tHk3JEvGOUq6h82L/hYpa0XtK+EbEuNVVsaLCOtenvw5L6gcMprrdUpcx+GyyzRtK2wG4M31zTbk1jjognaia/CpxfQVyj5aErR6hH6uJwurGeNtKr9beREdfrbm++zm3YvyXA7PR8NrDF2b6k3SXtkJ5PAI6h+p++K7PfarflJOD2SD0YOqRpzEOu2ZwArKgwvpFaApyRemtOAzYONrvaqHRLXRxON9bTRnq1/jYy8nrd6V5sw/Ruew/F0cYLwHrgO2n+fsDNQ3q5/Yri6PaTHY55T+A24MH0d480fyrwtfT8T4DlFL0PlwNndijWLfYb8FnghPR8R+DrwErgR8CBGXwmmsX8j8ADad8uBV6XQcxXAeuAP6TP85nAWcBZabmAi9M2LafBnQZ+bPV+75q62GQ7uq6ejmJbsqu/w2xL2+q1h9k0MzPLRLc3X5uZmfUMJ2UzM7NMOCmbmZllwknZzMwsE07KZmZmmXBSNjMzy4STspmZWSb+PwazLh3DuU9NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select a brand\n",
    "BRAND = 'nokia'\n",
    "\n",
    "## Get only the rows for the selected brand\n",
    "sel_brand = phrasesDF[phrasesDF['brand'] == BRAND]\n",
    "# Remove the neutral sentiment phrases, which tend to obscure the charts in our study\n",
    "sel_brand = sel_brand.query('text_sentiment < -0.1 or text_sentiment > 0.1')  \n",
    "\n",
    "# Create sentiment dataframes for each of the relevant aspects\n",
    "sel_brand_battery = sel_brand[sel_brand['aspect'] == 'battery']['text_sentiment']\n",
    "sel_brand_screen = sel_brand[sel_brand['aspect'] == 'screen']['text_sentiment']\n",
    "sel_brand_camera = sel_brand[sel_brand['aspect'] == 'camera']['text_sentiment']\n",
    "sel_brand_performance = sel_brand[sel_brand['aspect'] == 'performance']['text_sentiment']\n",
    "\n",
    "# Chart a histogram for each of the aspects\n",
    "import matplotlib\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(7,4))\n",
    "plt.tight_layout()\n",
    "\n",
    "axes[0,0].set_title(\"Screen\")\n",
    "axes[0,1].set_title(\"Camera\")\n",
    "axes[1,0].set_title(\"Battery\")\n",
    "axes[1,1].set_title(\"Performance\")\n",
    "\n",
    "sel_brand_screen.hist(ax=axes[0,0], bins=20)\n",
    "sel_brand_camera.hist(ax=axes[0,1])\n",
    "sel_brand_battery.hist(ax=axes[1,0], bins=20)\n",
    "sel_brand_performance.hist(ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "samsung           19906\n",
       "nokia              9773\n",
       "lg                 9518\n",
       "apple              9263\n",
       "motorola           6926\n",
       "sony               6652\n",
       "htc                5491\n",
       "posh mobile        5104\n",
       "blackberry         3884\n",
       "huawei             2905\n",
       "cnpgd              2466\n",
       "zte                1880\n",
       "lg electronics     1776\n",
       "alcatel            1718\n",
       "asus               1492\n",
       "otterbox           1028\n",
       "polaroid            797\n",
       "asus computers      673\n",
       "verykool            611\n",
       "Name: phrase, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topBrandsDF = phrasesDF.groupby(['brand']).count()\n",
    "topBrandsDF = topBrandsDF['phrase'].sort_values(ascending = False)[1:20]\n",
    "topBrands = topBrandsDF.index.values\n",
    "topBrandsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_subjectivity(reviewsDF):\n",
    "    return TextBlob(reviewsDF).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasesDF[\"text_subjectivity\"] = phrasesDF.phrase.apply(detect_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>phrase</th>\n",
       "      <th>rating</th>\n",
       "      <th>aspect</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text-sentiment</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>text_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samsung</td>\n",
       "      <td>Then needed new battery well</td>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samsung</td>\n",
       "      <td>stay charged had buy new battery</td>\n",
       "      <td>2</td>\n",
       "      <td>battery</td>\n",
       "      <td>7</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samsung</td>\n",
       "      <td>But the camera works great the video</td>\n",
       "      <td>5</td>\n",
       "      <td>camera</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>samsung</td>\n",
       "      <td>also notice that battery life lasts little bit</td>\n",
       "      <td>5</td>\n",
       "      <td>battery</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samsung</td>\n",
       "      <td>battery life great</td>\n",
       "      <td>3</td>\n",
       "      <td>battery</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand                                           phrase  rating   aspect  \\\n",
       "0  samsung                    Then needed new battery well        2  battery   \n",
       "1  samsung                stay charged had buy new battery        2  battery   \n",
       "2  samsung            But the camera works great the video        5   camera   \n",
       "3  samsung  also notice that battery life lasts little bit        5  battery   \n",
       "4  samsung                              battery life great        3  battery   \n",
       "\n",
       "   review_id  text-sentiment  text_sentiment  text_subjectivity  \n",
       "0          6        0.136364        0.136364           0.454545  \n",
       "1          7        0.136364        0.136364           0.454545  \n",
       "2          8        0.800000        0.800000           0.750000  \n",
       "3          8       -0.187500       -0.187500           0.500000  \n",
       "4          9        0.800000        0.800000           0.750000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
